{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dialogue Environment using large language models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import gym\n",
    "from textworld.gym.spaces import Word\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from english_words import english_words_set\n",
    "from typing import Tuple, Any\n",
    "from transformers import BertPreTrainedModel\n",
    "from typing import Sequence, List, Union, Dict, Any, Optional, Set\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from transformers import Conversation\n",
    "import uuid\n",
    "import logging\n",
    "from transformers import pipeline\n",
    "from abcd.utils.sentence import Sentence, CustomConversation\n",
    "logging.getLogger(\"transformers.generation_utils\").setLevel(logging.ERROR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "class DialogueEnv(gym.Env):\n",
    "    \"\"\" Gym environment that represents a conversation with a user (a LLM). \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # NOTE: I was using these models before, until I found out about this\n",
    "        # `conversational` pipeline, which simplifies the code a lot.\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "        # self.model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "        self.user_pipeline = pipeline(\"conversational\")\n",
    "        # TODO: Figure out the vocabulary of ABCD / or of the tokenizer itself.\n",
    "        self.observation_space = Sentence(max_length=128)\n",
    "        self.action_space = Sentence(max_length=10)\n",
    "        self._conversation: CustomConversation\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        agent_prompt: str = \"Hello, How can I help you?\",\n",
    "        user_prompt: str = None,\n",
    "    ):\n",
    "        \"\"\" Start a new conversation, primed with the agent say `agent_prompt`, and the\n",
    "        user responding `user_prompt`.\n",
    "        When `user_prompt` is not given, it is generated from the language model.\n",
    "        \"\"\"\n",
    "        # TODO: Retrieve some kind of prompt to prime the LM from the ABCD dataset.\n",
    "        # prompt = get_prompt_from_ABCD()\n",
    "\n",
    "        # \"Prime\" the conversation with some dialogue, and mark it as completed.\n",
    "        # This seems to help the model a little bit.\n",
    "        self.conversation = Conversation(agent_prompt)\n",
    "        if user_prompt:\n",
    "            self.conversation.append_response(user_prompt)\n",
    "            self.conversation.mark_processed()\n",
    "        else:\n",
    "            # Generate the first user response.\n",
    "            self.conversation = self.user_pipeline(self.conversation)\n",
    "\n",
    "        first_user_response = self.conversation.generated_responses[-1]\n",
    "        return first_user_response\n",
    "\n",
    "    def step(self, action: str) -> Tuple[str, Any, bool, Dict]:\n",
    "        self.chat_history.append(action)\n",
    "        self.conversation.add_user_input(action)\n",
    "        # TODO: This `max_length=10_000` argument is random, but it seems to help it\n",
    "        # not repeat itself.\n",
    "        self.conversation = self.user_pipeline(self.conversation, max_length=10000)\n",
    "\n",
    "        user_response: str = self.conversation.generated_responses[-1]\n",
    "        \n",
    "        # Assign a reward based on the user's response:\n",
    "        reward: float = 0.0\n",
    "        if any(v in user_response for v in [\"Thanks\", \"Great!\", \"That works!\"]):\n",
    "            reward += 1\n",
    "        if any(\n",
    "            v in user_response\n",
    "            for v in [\n",
    "                \"I'm not sure what you mean\",\n",
    "                \"I don't understand\",\n",
    "                \"That's not helpful\",\n",
    "            ]\n",
    "        ):\n",
    "            reward -= 1\n",
    "\n",
    "        # End the conversation if:\n",
    "        # - the user doesn't respond\n",
    "        # - the conversation ends peacefully\n",
    "        # - the conversation derails too much.\n",
    "        user_response_lowercase = user_response.lower()\n",
    "        done = not user_response or any(\n",
    "            v.lower() in user_response_lowercase\n",
    "            for v in [\n",
    "                \"Good bye\",\n",
    "                \"Goodbye\",\n",
    "                \"You too!\",\n",
    "                \"Good night\",\n",
    "                \"have a good day\",\n",
    "            ]\n",
    "        )\n",
    "        return user_response, reward, done, {}\n",
    "\n",
    "    @property\n",
    "    def conversation(self) -> Conversation:\n",
    "        return self._conversation\n",
    "\n",
    "    @conversation.setter\n",
    "    def conversation(self, value: Conversation):\n",
    "        self._conversation = CustomConversation.wrap(\n",
    "            value, user_name=\"Agent\", bot_name=\"User\"\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "env = DialogueEnv()\n",
    "obs = env.reset(user_prompt=\"I'm having trouble with my laptop.\")\n",
    "print(env.conversation)\n",
    "\n",
    "done = False\n",
    "steps = 0\n",
    "while not done:\n",
    "    # Option 1: Get custom input from the 'agent':\n",
    "    try:\n",
    "        action = input(f\"Agent: \")\n",
    "        print(f\"Agent: {action}\")\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    # Option 2: Say random words to the user (not very helpful!)\n",
    "    # action = env.action_space.sample()\n",
    "    # print(f\"Agent: {action}\")\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(f\"User: {obs} \\t (Reward: {reward}, done: {done}, info: {info})\")\n",
    "    steps += 1\n",
    "\n",
    "    if steps > 10:\n",
    "        print(f\"Exiting since we reached {10} steps.\")\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conversation id: 900a0ed5-5e1c-42d4-9a76-5511a4c7843b\n",
      "Agent: Hello, How can I help you?\n",
      "User: I'm having trouble with my laptop.\n",
      "Agent: What kind of trouble?\n",
      "User: I can't connect to the internet. \t (Reward: 0.0, done: False, info: {})\n",
      "Agent: Have you tried turning it off and on again?\n",
      "User: I have. It's still not working. \t (Reward: 0.0, done: False, info: {})\n",
      "Agent: Try again now. Is it fixed?\n",
      "User: It's working now. \t (Reward: 0.0, done: False, info: {})\n",
      "Agent: Great!\n",
      "User: Thanks for the help! \t (Reward: 1.0, done: False, info: {})\n",
      "Agent: You're welcome, have a nice day!\n",
      "User: You too! \t (Reward: 0.0, done: True, info: {})\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('abcd': conda)"
  },
  "interpreter": {
   "hash": "28f4f48524332ce9f9431fd96e541a621330d075a783e63a52c689c476c22848"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}