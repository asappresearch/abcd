{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# BUG: This somehow doesn't select the right kernel!\n",
    "#!pip install --quiet -e ."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import gym\n",
    "from textworld.gym.spaces import Word\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from english_words import english_words_set\n",
    "from transformers import T5Tokenizer\n",
    "from typing import Tuple, Any\n",
    "from transformers import GPT2TokenizerFast\n",
    "from transformers import BertPreTrainedModel\n",
    "from typing import Sequence, List, Union, Dict, Any, Optional, Set\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from transformers import Conversation\n",
    "import uuid\n",
    "import logging\n",
    "from transformers import pipeline\n",
    "from abcd.utils.sentence import Sentence, CustomConversation\n",
    "logging.getLogger(\"transformers.generation_utils\").setLevel(logging.ERROR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "class DialogueEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "        # self.model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "        # self.text_generator = pipeline(\"text-generation\")\n",
    "        self.user_pipeline = pipeline(\"conversational\")\n",
    "\n",
    "        # self.pipeline = pipeline(\"text-generation\")\n",
    "        # TODO: Figure out the vocabulary of ABCD / or of the tokenizer itself.\n",
    "        # tokenizer_vocab = self.tokenizer.get_vocab()\n",
    "        # assert False, dict(list(tokenizer_vocab.items())[:30])\n",
    "        self.observation_space = Sentence(max_length=128)\n",
    "        self.action_space = Sentence(max_length=10)\n",
    "        # self.observation_space = Word(max_length=128, vocab=english_words_set)\n",
    "        # self.action_space = Word(max_length=20, vocab=english_words_set)\n",
    "        self._conversation: CustomConversation\n",
    "        self.conversation = Conversation()\n",
    "        self.prompt: str\n",
    "        self.prompt_ids: Tensor\n",
    "        self.chat_history: List[str] = []\n",
    "        self.chat_history_ids: Tensor\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        agent_prompt: str = \"Hello, How can I help you?\",\n",
    "        user_prompt: str = \"I'm having trouble with my laptop.\",\n",
    "    ):\n",
    "        # TODO: Retrieve some kind of prompt to prime the LM from the ABCD dataset.\n",
    "        # prompt = get_prompt_from_ABCD()\n",
    "\n",
    "        # \"Prime\" the conversation with some dialogue, and mark it as completed.\n",
    "        # This seems to help the model a little bit.\n",
    "        self.conversation = Conversation(agent_prompt)\n",
    "        if user_prompt:\n",
    "            self.conversation.append_response(user_prompt)\n",
    "            self.conversation.mark_processed()\n",
    "        else:\n",
    "            self.conversation = self.user_pipeline(self.conversation)\n",
    "\n",
    "        first_user_response = self.conversation.generated_responses[-1]\n",
    "        return first_user_response\n",
    "\n",
    "    def step(self, action: str) -> Tuple[str, Any, bool, Dict]:\n",
    "        self.chat_history.append(action)\n",
    "        self.conversation.add_user_input(action)\n",
    "        # TODO: At some point the language model keeps repeating the same thing over an\n",
    "        # over, not sure why exactly. Maybe it's always trying to recreate the whole\n",
    "        # conversation, and that's longer than the max_length of the generative model?\n",
    "        # IDEA: Truncate the conversation, hopefully that will help:\n",
    "        # self.conversation.past_user_inputs = self.conversation.past_user_inputs[-5:]\n",
    "        # self.conversation.generated_responses = self.conversation.generated_responses[-5:]\n",
    "\n",
    "        self.conversation = self.user_pipeline(self.conversation, max_length=10000)\n",
    "\n",
    "        user_response: str = self.conversation.generated_responses[-1]\n",
    "        reward: float = 0.0\n",
    "        if any(v in user_response for v in [\"Thanks\", \"Great!\", \"That works!\"]):\n",
    "            reward += 1\n",
    "        if any(\n",
    "            v in user_response\n",
    "            for v in [\n",
    "                \"I'm not sure what you mean\",\n",
    "                \"I don't understand\",\n",
    "                \"That's not helpful.\",\n",
    "            ]\n",
    "        ):\n",
    "            reward -= 1\n",
    "\n",
    "        # Kill the conversation if:\n",
    "        # - the user doesn't respond\n",
    "        # - the conversation ends peacefully\n",
    "        # - the conversation derails too much.\n",
    "        user_response_lowercase = user_response.lower()\n",
    "        done = not user_response or any(\n",
    "            v.lower() in user_response_lowercase\n",
    "            for v in [\n",
    "                \"Good bye\",\n",
    "                \"Goodbye\",\n",
    "                \"You too!\",\n",
    "                \"Good night\",\n",
    "                \"have a good day\",\n",
    "            ]\n",
    "        )\n",
    "        return user_response, reward, done, {}\n",
    "\n",
    "    @property\n",
    "    def conversation(self) -> Conversation:\n",
    "        return self._conversation\n",
    "\n",
    "    @conversation.setter\n",
    "    def conversation(self, value: Conversation):\n",
    "        self._conversation = CustomConversation.wrap(\n",
    "            value, user_name=\"Agent\", bot_name=\"User\"\n",
    "        )\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "env = DialogueEnv()\n",
    "obs = env.reset()\n",
    "print(env.conversation)\n",
    "\n",
    "done = False\n",
    "steps = 0\n",
    "while not done:\n",
    "    # Option 1: Get custom input from the 'agent':\n",
    "    try:\n",
    "        action = input(f\"Agent: \")\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    # Option 2: Say random words to the user (not very helpful!)\n",
    "    # action = env.action_space.sample()\n",
    "    # print(f\"Agent: {action}\")\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(f\"User: {obs} \\t (Reward: {reward}, done: {done}, info: {info})\")\n",
    "    steps += 1\n",
    "\n",
    "    if steps > 10:\n",
    "        print(f\"Exiting since we reached {10} steps.\")\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conversation id: 3c6ddea2-ed3f-491b-9ff8-7ffb4bfb8928\n",
      "Agent: Hello, How can I help you?\n",
      "User: I'm having trouble with my laptop.\n",
      "User: I can't connect to the internet. \t (Reward: 0.0, done: False, info: {})\n",
      "User: I have. It's still not working. \t (Reward: 0.0, done: False, info: {})\n",
      "User: It's working now. \t (Reward: 0.0, done: False, info: {})\n",
      "User: Thanks for the help! \t (Reward: 1.0, done: False, info: {})\n",
      "User: You too! \t (Reward: 0.0, done: True, info: {})\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('abcd': conda)"
  },
  "interpreter": {
   "hash": "28f4f48524332ce9f9431fd96e541a621330d075a783e63a52c689c476c22848"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}